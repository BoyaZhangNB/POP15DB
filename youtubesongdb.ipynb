{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U yt_dlp;\n",
    "!huggingface-cli login --token <YOURTOKEN>\n",
    "!pip install stempeg\n",
    "!pip install torchsde\n",
    "!pip install -U demucs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import torch\n",
    "print(\"CUDA availability: \", torch.cuda.is_available())\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import yt_dlp\n",
    "import concurrent.futures\n",
    "import csv\n",
    "import demucs.separate\n",
    "import logging\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from diffusers import StableAudioPipeline\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import stempeg\n",
    "import soundfile as sf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io.wavfile as wavfile\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getSongTitle():    \n",
    "    song_titles = []\n",
    "    csv_file_path = \"/kaggle/input/song-popularity-dataset/song_data.csv\"\n",
    "    # Append 'title' and 'artist' columns from the CSV to song_titles\n",
    "    try:\n",
    "        with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                name = row['song_name']\n",
    "                if len(name.split()) == 1:\n",
    "                    name = name + \" - Music Video\"\n",
    "                song_titles.append(name)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing CSV file: {e}\")\n",
    "    \n",
    "    print(f\"Number of songs: {len(song_titles)}\")\n",
    "    return song_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def download_song(title, ydl_opts):\n",
    "    query = f\"ytsearch1:{title}\"\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([query])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading {title}: {e}\")\n",
    "\n",
    "\n",
    "def downloadBatch(song_title_batch, output_folder):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': os.path.join(output_folder, '%(title)s.%(ext)s'),\n",
    "        'noplaylist': True,\n",
    "        'quiet': True,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'postprocessor_args': [\n",
    "            '-ar', '44100'  # Set audio sampling rate to 44.1kHz\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for title in song_title_batch:\n",
    "        download_song(title, ydl_opts)\n",
    "        # print(\"Song downloaded from Youtube: \", title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate vocal and accompaniment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seperate(output_folder, device):\n",
    "    # List all .wav files in the downloads folder\n",
    "    wav_files = [f for f in os.listdir(output_folder) if f.lower().endswith('.wav')]\n",
    "\n",
    "    logging.getLogger('demucs').setLevel(logging.CRITICAL)\n",
    "    \n",
    "    for wav_file in wav_files:\n",
    "        wav_path = os.path.join(output_folder, wav_file)\n",
    "        # print(f\"üé∂ Separating: {wav_file}\")\n",
    "        demucs.separate.main([\n",
    "            \"--two-stems\", \"vocals\", \"--device\", device, \"-n\", \"mdx_extra\", wav_path\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load seperated vocals and accompaniment to Torch Dataset\n",
    "- Apply chunking to regulate the latent audio length\n",
    "- Calculate total audio length and compute index\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========UTILS==========\n",
    "def clear_directory(base_dir):\n",
    "    \"\"\"\n",
    "    Deletes all files and subdirectories in the given base directory.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Path to the base directory to clear.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(base_dir):\n",
    "        raise ValueError(f\"{base_dir} is not a valid directory.\")\n",
    "\n",
    "    for entry in os.listdir(base_dir):\n",
    "        entry_path = os.path.join(base_dir, entry)\n",
    "        try:\n",
    "            if os.path.isfile(entry_path) or os.path.islink(entry_path):\n",
    "                os.unlink(entry_path)  # Remove file or symlink\n",
    "            elif os.path.isdir(entry_path):\n",
    "                shutil.rmtree(entry_path)  # Recursively delete folder\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {entry_path}: {e}\")\n",
    "\n",
    "def get_wav_length(file_path):\n",
    "    with sf.SoundFile(file_path) as f:\n",
    "        duration = len(f) / f.samplerate\n",
    "    # print(duration)\n",
    "    return duration\n",
    "    \n",
    "def load_wav_as_array(path):\n",
    "    audio, sr = sf.read(path, dtype='float32')\n",
    "    return audio\n",
    "\n",
    "def load_vocal_and_accmp(song_dir):\n",
    "    vocal = load_wav_as_array(os.path.join(song_dir, \"vocals.wav\"))\n",
    "    accmp = load_wav_as_array(os.path.join(song_dir, \"no_vocals.wav\"))\n",
    "    return vocal, accmp\n",
    "\n",
    "class PopSepDB(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.song_names = [song_name for song_name in os.listdir(root_dir)]\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        chunk_per_song = []\n",
    "        for song in self.song_names:\n",
    "            vocal_path = os.path.join(root_dir, song, \"vocals.wav\")\n",
    "            dur = get_wav_length(vocal_path)\n",
    "            chunk_per_song.append(int(dur/48))\n",
    "\n",
    "        self.total_chunks = sum(chunk_per_song)\n",
    "        self.cumchunk = np.cumsum(chunk_per_song)\n",
    "        print(self.cumchunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_chunks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        song, chunk = self.compute_idx(idx)\n",
    "        print(\"Song: \", song, \" Chunk: \",chunk)\n",
    "        \n",
    "        song_name = self.song_names[song]\n",
    "        song_dir = os.path.join(self.root_dir, song_name)\n",
    "\n",
    "        vocal, accompaniment = load_vocal_and_accmp(song_dir)\n",
    "\n",
    "        vocal = vocal.transpose(1, 0)\n",
    "        accompaniment = accompaniment.transpose(1, 0)\n",
    "        \n",
    "        start = 2097152 * chunk\n",
    "        \n",
    "        # Returns array with shape (2, 2097152)\n",
    "        return vocal[:, start:start+2097152], accompaniment[:, start:start+2097152]\n",
    "\n",
    "\n",
    "    def compute_idx(self, idx):\n",
    "        for i in range(len(self.cumchunk)):\n",
    "            if idx < self.cumchunk[i]:\n",
    "                return(i, (idx-self.cumchunk[i-1]) if i>0 else idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the song with autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_encoder(device):\n",
    "    #login(new_session=False)\n",
    "    \n",
    "    REPO = \"stabilityai/stable-audio-open-1.0\"\n",
    "    dtype = torch.float32\n",
    "\n",
    "    pipe = StableAudioPipeline.from_pretrained(REPO, torch_dtype=dtype)\n",
    "    autoencoder = pipe.vae.to(device)\n",
    "\n",
    "    print(\"Autoencoder loaded\")\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode(latent_vocals, latent_accomp, dataloader, autoencoder, device=\"cpu\"):\n",
    "    # print(\"encoding stems...\")\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        \n",
    "        vocals, accompaniment = batch # expand first dimension to match expected input shape\n",
    "        \n",
    "        vocals = vocals.to(device).to(torch.float32)\n",
    "        accompaniment = accompaniment.to(device).to(torch.float32)\n",
    "    \n",
    "        # Encode the vocals and accompaniment using the autoencoder\n",
    "        with torch.no_grad():\n",
    "            encoded_vocals = autoencoder.encode(vocals).latent_dist.mode()\n",
    "            encoded_accompaniment = autoencoder.encode(accompaniment).latent_dist.mode()\n",
    "    \n",
    "        if torch.isnan(encoded_vocals).any():\n",
    "            print(\"===============NaN in vocals==============\")\n",
    "            continue\n",
    "        \n",
    "        # Print shapes of the encoded outputs\n",
    "        # print(f\"Encoded Vocals Shape: {encoded_vocals.shape}\") # (BATCH, 64, 1024)\n",
    "        # print(f\"Encoded Accompaniment Shape: {encoded_accompaniment.shape}\") # (BATCH, 64, 1024)\n",
    "    \n",
    "        latent_vocals.extend(encoded_vocals.cpu().numpy())\n",
    "        latent_accomp.extend(encoded_accompaniment.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure the folder exists\n",
    "output_folder = \"downloads\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "BATCHSIZE = 1\n",
    "SONGBATCH = 16\n",
    "\n",
    "song_titles = getSongTitle()\n",
    "autoencoder = load_encoder(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latent_vocals = []\n",
    "latent_accomp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(song_titles) // SONGBATCH - 1):\n",
    "for i in range(2):\n",
    "\n",
    "    start = i * SONGBATCH\n",
    "    end = (i + 1) * SONGBATCH\n",
    "    \n",
    "    # Download wav file from youtube\n",
    "    downloadBatch(song_titles[start:end], output_folder)\n",
    "    \n",
    "    # Seperate with Demucs\n",
    "    seperate(output_folder, device)\n",
    "    \n",
    "    dataset = PopSepDB(\"/kaggle/working/separated/mdx_extra\")\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCHSIZE, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    encode(latent_vocals, latent_accomp, dataloader, autoencoder, device=device)\n",
    "    # Convert to numpy array and print shape\n",
    "    np.save('latent_vocals.npy', latent_vocals) #  (N, 64, 1024)\n",
    "    np.save('latent_accomp.npy', latent_accomp) #  (N, 64, 1024)\n",
    "\n",
    "    clear_directory(\"/kaggle/working/downloads\")\n",
    "    clear_directory(\"/kaggle/working/separated\")\n",
    "\n",
    "    print(f\"Encode Completed - Batch: {i} | Song: {end} | latent vector shape: {len(latent_vocals)} and {len(latent_accomp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "kaggle/working/\n",
    "‚îú‚îÄ‚îÄ latent_vocals.npy [~1.3MB per songs]\n",
    "‚îú‚îÄ‚îÄ latent_accomp.npy\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ downloads/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Bohemian Rhapsody Queen.wav\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Blinding Lights The Weeknd.wav\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Imagine John Lennon.wav  \n",
    "‚îÇ   ‚îÇ\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ separated/\n",
    "    ‚îî‚îÄ‚îÄ mdx_extra/\n",
    "        ‚îú‚îÄ‚îÄ track1/\n",
    "        ‚îÇ   ‚îú‚îÄ‚îÄ vocals.wav\n",
    "        ‚îÇ   ‚îî‚îÄ‚îÄ accompaniment.wav\n",
    "        ‚îú‚îÄ‚îÄ track2/\n",
    "        ‚îÇ   ‚îú‚îÄ‚îÄ vocals.wav\n",
    "        ‚îÇ   ‚îî‚îÄ‚îÄ no_vocals.wav\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1847235,
     "sourceId": 3015803,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
